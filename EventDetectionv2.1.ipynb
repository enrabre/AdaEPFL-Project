{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import math\n",
    "from collections import Counter\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import re\n",
    "import copy\n",
    "import json\n",
    "from datetime import timedelta\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def now():\n",
    "    return str(datetime.now().time())[:8]\n",
    "def pr(strToPrint):\n",
    "    print(now() + ' '+ strToPrint)\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = 'beep.wav'\n",
    "# pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing a sample of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_filename = os.path.join('data','head_100k_pickle.pkl')\n",
    "tw = pd.read_pickle(pickle_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:35:07 Starting to read file... (3 min)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\Anaconda3\\envs\\ADA-kernel\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (0,1,2,3,5,6,8,9,10,11,12,13,14,15,16,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:37:34 File is loaded!\n"
     ]
    }
   ],
   "source": [
    "columns_header = ['id', 'userId', 'createdAt', 'text', 'longitude', 'latitude', 'placeId',\n",
    "                  'inReplyTo', 'source', 'truncated', 'placeLatitude', 'placeLongitude', 'sourceName', 'sourceUrl',\n",
    "                 'userName', 'screenName', 'followersCount', 'friendsCount', 'statusesCount',\n",
    "                 'userLocation']\n",
    "\n",
    "filename = os.path.join('data','twex.tsv') # 'sample.tsv')\n",
    "pr('Starting to read file... (3 min)')\n",
    "tw = pd.read_csv(filename, sep='\\t', encoding='utf-8', escapechar='\\\\', names=columns_header,\n",
    "                      quoting=csv.QUOTE_NONE, na_values='N', header=None)\n",
    "\n",
    "pr('File is loaded!')\n",
    "# Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userId</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>text</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>placeId</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>placeLatitude</th>\n",
       "      <th>placeLongitude</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>userName</th>\n",
       "      <th>screenName</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "      <th>userLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9514097914</td>\n",
       "      <td>1.7341e+07</td>\n",
       "      <td>2010-02-23 05:55:51</td>\n",
       "      <td>Guuuuten Morgen! :-)</td>\n",
       "      <td>7.43926</td>\n",
       "      <td>46.9489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TwitBird</td>\n",
       "      <td>http://www.nibirutech.com</td>\n",
       "      <td>Tilman Jentzsch</td>\n",
       "      <td>blickwechsel</td>\n",
       "      <td>586</td>\n",
       "      <td>508.0</td>\n",
       "      <td>9016.0</td>\n",
       "      <td>Bern, Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9514846412</td>\n",
       "      <td>7.19828e+06</td>\n",
       "      <td>2010-02-23 06:22:40</td>\n",
       "      <td>Still the best coffee in town — at La Stanza h...</td>\n",
       "      <td>8.53781</td>\n",
       "      <td>47.3678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gowalla</td>\n",
       "      <td>http://gowalla.com/</td>\n",
       "      <td>Nico Luchsinger</td>\n",
       "      <td>halbluchs</td>\n",
       "      <td>1820</td>\n",
       "      <td>703.0</td>\n",
       "      <td>4687.0</td>\n",
       "      <td>Zurich, Switzerland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       userId            createdAt  \\\n",
       "0  9514097914   1.7341e+07  2010-02-23 05:55:51   \n",
       "1  9514846412  7.19828e+06  2010-02-23 06:22:40   \n",
       "\n",
       "                                                text  longitude latitude  \\\n",
       "0                               Guuuuten Morgen! :-)    7.43926  46.9489   \n",
       "1  Still the best coffee in town — at La Stanza h...    8.53781  47.3678   \n",
       "\n",
       "  placeId  inReplyTo source truncated placeLatitude placeLongitude sourceName  \\\n",
       "0     NaN        NaN    197       NaN           NaN            NaN   TwitBird   \n",
       "1     NaN        NaN    550       NaN           NaN            NaN    Gowalla   \n",
       "\n",
       "                   sourceUrl         userName    screenName followersCount  \\\n",
       "0  http://www.nibirutech.com  Tilman Jentzsch  blickwechsel            586   \n",
       "1        http://gowalla.com/  Nico Luchsinger     halbluchs           1820   \n",
       "\n",
       "   friendsCount  statusesCount         userLocation  \n",
       "0         508.0         9016.0    Bern, Switzerland  \n",
       "1         703.0         4687.0  Zurich, Switzerland  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrating hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_hashtags(text):\n",
    "    ht_list = re.findall(r\"#(\\w+)\", text)\n",
    "    non_empty_hts = list(filter((lambda ht: ht != []), ht_list))\n",
    "    lowerCharList = [ht.lower() for ht in non_empty_hts]\n",
    "    return lowerCharList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:37:34 Making hashtags... (2 min)\n",
      "11:39:25 Done.\n"
     ]
    }
   ],
   "source": [
    "pr('Making hashtags... (2 min)')\n",
    "tw['hashtag'] = np.nan\n",
    "tw.hashtag = tw.text.apply(lambda x: extract_hashtags(str(x)))\n",
    "twh = tw.ix[tw.hashtag.apply(lambda x: len(x) != 0)]\n",
    "pr('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userId</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>text</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>placeId</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>...</th>\n",
       "      <th>placeLongitude</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>userName</th>\n",
       "      <th>screenName</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9519737890</td>\n",
       "      <td>1.46579e+07</td>\n",
       "      <td>2010-02-23 09:59:41</td>\n",
       "      <td>Magic spells run off after midnight, I guess s...</td>\n",
       "      <td>6.13870</td>\n",
       "      <td>46.175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/#!/download/iphone</td>\n",
       "      <td>Javier Belmonte</td>\n",
       "      <td>vichango</td>\n",
       "      <td>167</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>Geneva, Switzerland</td>\n",
       "      <td>[fb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9521789689</td>\n",
       "      <td>9.96202e+06</td>\n",
       "      <td>2010-02-23 11:28:27</td>\n",
       "      <td>Limitas of public transportation! No taxi, rai...</td>\n",
       "      <td>6.33641</td>\n",
       "      <td>46.4631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gowalla</td>\n",
       "      <td>http://gowalla.com/</td>\n",
       "      <td>Thomas Winter</td>\n",
       "      <td>thwinter</td>\n",
       "      <td>1070</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>3349.0</td>\n",
       "      <td>Hettlingen CH / SanJose Ca</td>\n",
       "      <td>[yam]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       userId            createdAt  \\\n",
       "8   9519737890  1.46579e+07  2010-02-23 09:59:41   \n",
       "10  9521789689  9.96202e+06  2010-02-23 11:28:27   \n",
       "\n",
       "                                                 text  longitude latitude  \\\n",
       "8   Magic spells run off after midnight, I guess s...    6.13870   46.175   \n",
       "10  Limitas of public transportation! No taxi, rai...    6.33641  46.4631   \n",
       "\n",
       "   placeId  inReplyTo source truncated   ...   placeLongitude  \\\n",
       "8      NaN        NaN      1       NaN   ...              NaN   \n",
       "10     NaN        NaN    550       NaN   ...              NaN   \n",
       "\n",
       "            sourceName                              sourceUrl  \\\n",
       "8   Twitter for iPhone  http://twitter.com/#!/download/iphone   \n",
       "10             Gowalla                    http://gowalla.com/   \n",
       "\n",
       "           userName screenName followersCount friendsCount  statusesCount  \\\n",
       "8   Javier Belmonte   vichango            167        277.0         2885.0   \n",
       "10    Thomas Winter   thwinter           1070       1359.0         3349.0   \n",
       "\n",
       "                  userLocation hashtag  \n",
       "8          Geneva, Switzerland    [fb]  \n",
       "10  Hettlingen CH / SanJose Ca   [yam]  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twh.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data and making date index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data have been reduced from 3875280 tweets to 3875280 tweets.\n"
     ]
    }
   ],
   "source": [
    "tw1 = twh.dropna(axis=0, how='any', subset=['text', 'createdAt'])\n",
    "print('The data have been reduced from {} tweets to {} tweets.'.format(len(twh), len(tw1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:39:28 Removing bad dates...\n",
      "11:39:31 Finished.\n"
     ]
    }
   ],
   "source": [
    "pr('Removing bad dates...')\n",
    "twhCleanDate = tw1[tw1['createdAt'].str.len() == 19]\n",
    "pr('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:39:31 Starting to examine dates...\n",
      "11:39:33 There are 0 dates that cannot be transformed.\n"
     ]
    }
   ],
   "source": [
    "pr('Starting to examine dates...')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "datetime_serie = twhCleanDate['createdAt'].convert_objects(convert_dates='coerce')\n",
    "dateNotConvertible = datetime_serie[pd.isnull(datetime_serie)]\n",
    "warnings.filterwarnings('default')\n",
    "pr('There are {} dates that cannot be transformed.'.format(len(dateNotConvertible)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:39:33 Starting copy...\n",
      "11:39:34 Converting to datetime...\n",
      "11:39:37 Setting up new indices...\n",
      "11:39:37 Deleting old \"createdAt\" column...\n",
      "11:39:37 Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userId</th>\n",
       "      <th>text</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>placeId</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>placeLatitude</th>\n",
       "      <th>placeLongitude</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>userName</th>\n",
       "      <th>screenName</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>createdAt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-23 09:59:41</th>\n",
       "      <td>9519737890</td>\n",
       "      <td>1.46579e+07</td>\n",
       "      <td>Magic spells run off after midnight, I guess s...</td>\n",
       "      <td>6.13870</td>\n",
       "      <td>46.175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/#!/download/iphone</td>\n",
       "      <td>Javier Belmonte</td>\n",
       "      <td>vichango</td>\n",
       "      <td>167</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>Geneva, Switzerland</td>\n",
       "      <td>[fb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-23 11:28:27</th>\n",
       "      <td>9521789689</td>\n",
       "      <td>9.96202e+06</td>\n",
       "      <td>Limitas of public transportation! No taxi, rai...</td>\n",
       "      <td>6.33641</td>\n",
       "      <td>46.4631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gowalla</td>\n",
       "      <td>http://gowalla.com/</td>\n",
       "      <td>Thomas Winter</td>\n",
       "      <td>thwinter</td>\n",
       "      <td>1070</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>3349.0</td>\n",
       "      <td>Hettlingen CH / SanJose Ca</td>\n",
       "      <td>[yam]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id       userId  \\\n",
       "createdAt                                      \n",
       "2010-02-23 09:59:41  9519737890  1.46579e+07   \n",
       "2010-02-23 11:28:27  9521789689  9.96202e+06   \n",
       "\n",
       "                                                                  text  \\\n",
       "createdAt                                                                \n",
       "2010-02-23 09:59:41  Magic spells run off after midnight, I guess s...   \n",
       "2010-02-23 11:28:27  Limitas of public transportation! No taxi, rai...   \n",
       "\n",
       "                     longitude latitude placeId  inReplyTo source truncated  \\\n",
       "createdAt                                                                     \n",
       "2010-02-23 09:59:41    6.13870   46.175     NaN        NaN      1       NaN   \n",
       "2010-02-23 11:28:27    6.33641  46.4631     NaN        NaN    550       NaN   \n",
       "\n",
       "                    placeLatitude placeLongitude          sourceName  \\\n",
       "createdAt                                                              \n",
       "2010-02-23 09:59:41           NaN            NaN  Twitter for iPhone   \n",
       "2010-02-23 11:28:27           NaN            NaN             Gowalla   \n",
       "\n",
       "                                                 sourceUrl         userName  \\\n",
       "createdAt                                                                     \n",
       "2010-02-23 09:59:41  http://twitter.com/#!/download/iphone  Javier Belmonte   \n",
       "2010-02-23 11:28:27                    http://gowalla.com/    Thomas Winter   \n",
       "\n",
       "                    screenName followersCount  friendsCount  statusesCount  \\\n",
       "createdAt                                                                    \n",
       "2010-02-23 09:59:41   vichango            167         277.0         2885.0   \n",
       "2010-02-23 11:28:27   thwinter           1070        1359.0         3349.0   \n",
       "\n",
       "                                   userLocation hashtag  \n",
       "createdAt                                                \n",
       "2010-02-23 09:59:41         Geneva, Switzerland    [fb]  \n",
       "2010-02-23 11:28:27  Hettlingen CH / SanJose Ca   [yam]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr('Starting copy...') # (to avoid transformation problems)\n",
    "tw5 = twhCleanDate.copy()\n",
    "pr('Converting to datetime...')\n",
    "tw5['createdAt'] = pd.to_datetime(twhCleanDate['createdAt'])\n",
    "pr('Setting up new indices...')\n",
    "tw5.index = tw5['createdAt']\n",
    "pr('Deleting old \"createdAt\" column...')\n",
    "del tw5['createdAt']\n",
    "pr('Done!')\n",
    "tw5.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createdAt\n",
       "2010-02-23 09:59:41               [fb]\n",
       "2010-02-23 11:28:27              [yam]\n",
       "2010-02-23 17:47:11          [24, vfb]\n",
       "2010-02-23 18:19:03    [iphoneography]\n",
       "2010-02-23 18:31:46     [partnermonth]\n",
       "2010-02-24 06:09:23      [insider, fb]\n",
       "Name: hashtag, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw5['hashtag'][:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's put one hashtag per row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will make a dataframe with one row = one hashtag. This will be done by going through the dataframe, and making in parallel a list of rows (with 1 hashtag per row) that needs to be added to the old dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addedHashtagsRowsList = []\n",
    "def multiplyHashtagRows(row, columns):\n",
    "    '''\n",
    "    Examine each row. If there are multiple hashtags, it will return the first one.\n",
    "    (so the first one will replace the list of hashtags in the df). Then for all the next ones,\n",
    "    it will make a copy of the row in the addedHashtagsRowsList, (in a dictionary format).\n",
    "    So this dictionary can in the end be transformed in a DF and added to the original DF.\n",
    "    (The speed is increased a lot by doing it this way!)\n",
    "    '''\n",
    "    htList = row.hashtag\n",
    "    if len(htList) > 1:\n",
    "        ## Making the dictionary\n",
    "        addedHashtag = {}\n",
    "        addedHashtag['createdAt'] = row.name #the df index\n",
    "        for col in columns:\n",
    "            addedHashtag[col] = row[col]\n",
    "        ## Copying the dict for each hashtag\n",
    "        i = 1\n",
    "        while i < len(htList) :\n",
    "            deepCopy = copy.deepcopy(addedHashtag)\n",
    "            deepCopy['hashtag'] = htList[i]\n",
    "            addedHashtagsRowsList.append(deepCopy)\n",
    "            i+=1\n",
    "    return htList[0] # return the first hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:39:38 Multiplying the hashtag rows... (around 10 min)\n",
      "11:48:37 Finished! 3350600 rows will be added to the dataframe!\n"
     ]
    }
   ],
   "source": [
    "addedHashtagsRowsList = []\n",
    "tw5_1 = tw5.copy()\n",
    "pr('Multiplying the hashtag rows... (around 10 min)')\n",
    "tw5_1['hashtag'] = tw5.apply(multiplyHashtagRows, args=[tw5.columns,], axis=1)\n",
    "pr('Finished! {} rows will be added to the dataframe!'.format(len(addedHashtagsRowsList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:48:37 Starting to make the new dataframe with additionnal rows..\n",
      "11:48:50 Starting to append the two df... Old df size = 3875280\n",
      "11:48:56 Done! New df size = 7225880\n"
     ]
    }
   ],
   "source": [
    "pr('Starting to make the new dataframe with additionnal rows..')\n",
    "addedHashtagsDf = pd.DataFrame(addedHashtagsRowsList)\n",
    "addedHashtagsDf.set_index(['createdAt'], inplace=True)\n",
    "pr('Starting to append the two df... Old df size = {}'.format(len(tw5_1)))\n",
    "tw6 = tw5_1.append(addedHashtagsDf)\n",
    "pr('Done! New df size = {}'.format(len(tw6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example hahshtag:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>placeId</th>\n",
       "      <th>placeLatitude</th>\n",
       "      <th>placeLongitude</th>\n",
       "      <th>screenName</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>statusesCount</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>userId</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>createdAt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-07-24 16:03:13</th>\n",
       "      <td>1121</td>\n",
       "      <td>763.0</td>\n",
       "      <td>vfb</td>\n",
       "      <td>95162125584039936</td>\n",
       "      <td>9.501397e+16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e401fb8eb4e7595a</td>\n",
       "      <td>47.5356</td>\n",
       "      <td>9.14004</td>\n",
       "      <td>eLd0raDo</td>\n",
       "      <td>14</td>\n",
       "      <td>Tweetbot for iOS</td>\n",
       "      <td>http://tapbots.com/tweetbot</td>\n",
       "      <td>6735.0</td>\n",
       "      <td>@mikstweed Wie lange ist es her, dass der #vfb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>921241</td>\n",
       "      <td>Kreuzlingen, TG, Switzerland</td>\n",
       "      <td>Markus Tressl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-29 16:15:54</th>\n",
       "      <td>1008</td>\n",
       "      <td>767.0</td>\n",
       "      <td>vfb</td>\n",
       "      <td>229611214802669570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.6683</td>\n",
       "      <td>9.48077</td>\n",
       "      <td>7e00050f2f9230bc</td>\n",
       "      <td>47.6684</td>\n",
       "      <td>9.47092</td>\n",
       "      <td>jens_nagler</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/#!/download/iphone</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>Man sollte ja nicht zu viel reininterpretieren...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.71385e+07</td>\n",
       "      <td>Esslingen</td>\n",
       "      <td>Jens Nagler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-29 16:21:45</th>\n",
       "      <td>1008</td>\n",
       "      <td>767.0</td>\n",
       "      <td>vfb</td>\n",
       "      <td>229612686525231104</td>\n",
       "      <td>2.296124e+17</td>\n",
       "      <td>47.6682</td>\n",
       "      <td>9.48068</td>\n",
       "      <td>7e00050f2f9230bc</td>\n",
       "      <td>47.6684</td>\n",
       "      <td>9.47092</td>\n",
       "      <td>jens_nagler</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/#!/download/iphone</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>@LLcurly Das Besondere daran ist, dass nur zwe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.71385e+07</td>\n",
       "      <td>Esslingen</td>\n",
       "      <td>Jens Nagler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    followersCount  friendsCount hashtag                  id  \\\n",
       "createdAt                                                                      \n",
       "2011-07-24 16:03:13           1121         763.0     vfb   95162125584039936   \n",
       "2012-07-29 16:15:54           1008         767.0     vfb  229611214802669570   \n",
       "2012-07-29 16:21:45           1008         767.0     vfb  229612686525231104   \n",
       "\n",
       "                        inReplyTo latitude  longitude           placeId  \\\n",
       "createdAt                                                                 \n",
       "2011-07-24 16:03:13  9.501397e+16      NaN        NaN  e401fb8eb4e7595a   \n",
       "2012-07-29 16:15:54           NaN  47.6683    9.48077  7e00050f2f9230bc   \n",
       "2012-07-29 16:21:45  2.296124e+17  47.6682    9.48068  7e00050f2f9230bc   \n",
       "\n",
       "                    placeLatitude placeLongitude   screenName source  \\\n",
       "createdAt                                                              \n",
       "2011-07-24 16:03:13       47.5356        9.14004     eLd0raDo     14   \n",
       "2012-07-29 16:15:54       47.6684        9.47092  jens_nagler      1   \n",
       "2012-07-29 16:21:45       47.6684        9.47092  jens_nagler      1   \n",
       "\n",
       "                             sourceName  \\\n",
       "createdAt                                 \n",
       "2011-07-24 16:03:13    Tweetbot for iOS   \n",
       "2012-07-29 16:15:54  Twitter for iPhone   \n",
       "2012-07-29 16:21:45  Twitter for iPhone   \n",
       "\n",
       "                                                 sourceUrl  statusesCount  \\\n",
       "createdAt                                                                   \n",
       "2011-07-24 16:03:13            http://tapbots.com/tweetbot         6735.0   \n",
       "2012-07-29 16:15:54  http://twitter.com/#!/download/iphone         1697.0   \n",
       "2012-07-29 16:21:45  http://twitter.com/#!/download/iphone         1697.0   \n",
       "\n",
       "                                                                  text  \\\n",
       "createdAt                                                                \n",
       "2011-07-24 16:03:13  @mikstweed Wie lange ist es her, dass der #vfb...   \n",
       "2012-07-29 16:15:54  Man sollte ja nicht zu viel reininterpretieren...   \n",
       "2012-07-29 16:21:45  @LLcurly Das Besondere daran ist, dass nur zwe...   \n",
       "\n",
       "                    truncated       userId                  userLocation  \\\n",
       "createdAt                                                                  \n",
       "2011-07-24 16:03:13       NaN       921241  Kreuzlingen, TG, Switzerland   \n",
       "2012-07-29 16:15:54       NaN  5.71385e+07                     Esslingen   \n",
       "2012-07-29 16:21:45       NaN  5.71385e+07                     Esslingen   \n",
       "\n",
       "                          userName  \n",
       "createdAt                           \n",
       "2011-07-24 16:03:13  Markus Tressl  \n",
       "2012-07-29 16:15:54    Jens Nagler  \n",
       "2012-07-29 16:21:45    Jens Nagler  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Example hahshtag:')\n",
    "tw6[tw6['hashtag'] == addedHashtagsRowsList[0]['hashtag']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createdAt\n",
       "2010-02-23 09:59:41               fb\n",
       "2010-02-23 11:28:27              yam\n",
       "2010-02-23 17:47:11               24\n",
       "2010-02-23 18:19:03    iphoneography\n",
       "2010-02-23 18:31:46     partnermonth\n",
       "Name: hashtag, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw6.hashtag.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping per hashtags per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw6.dropna(subset=['longitude'], inplace=True)\n",
    "tw6.dropna(subset=['latitude'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw6.latitude = tw6.latitude.apply(float)\n",
    "tw6.longitude = tw6.longitude.apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delimiter = '_$$$_'\n",
    "str_join = lambda x: delimiter.join(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that applies to a dataframe will group each row by day and aggregate all its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def aggDate(df):\n",
    "    groupedDf = df.groupby(df.index.map(lambda x: x.date)).agg({'text' : str_join,\n",
    "                                                          'longitude' : np.median,\n",
    "                                                          'latitude' : np.median,\n",
    "                                                          'hashtag' : lambda x: x.iloc[0], ## the first occurence\n",
    "                                                          'numberOfTweets' : 'count'})\n",
    "    return groupedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:49:11 Making column number of tweets\n",
      "11:49:11 Starting group by hastag...\n",
      "11:49:11 Starting to put hashtag in dictionary... (around 50 min)\n",
      "11:54:20 10%\n",
      "11:58:57 20%\n",
      "12:03:30 30%\n",
      "12:08:06 40%\n",
      "12:12:42 50%\n",
      "12:17:17 60%\n",
      "12:21:49 70%\n",
      "12:26:22 80%\n",
      "12:30:55 90%\n",
      "12:35:24 100%\n",
      "12:35:24 Finished operations! Dictionary with 607601 different hashtags.\n"
     ]
    }
   ],
   "source": [
    "pr('Making column number of tweets')\n",
    "tw6['numberOfTweets'] = 1\n",
    "pr('Starting group by hastag...')\n",
    "gp = tw6.groupby('hashtag')\n",
    "pr('Starting to put hashtag in dictionary... (around 50 min)')\n",
    "\n",
    "count = 0\n",
    "lengp = len(gp)\n",
    "printingValue = int(lengp / 10)\n",
    "dictionary = {}\n",
    "for hashtag, df in gp:\n",
    "    dictionary[hashtag] = aggDate(df)\n",
    "    count += 1\n",
    "    if count % printingValue == 0:\n",
    "        pr(\"{:.0f}%\".format(count/lengp*100))\n",
    "pr('Finished operations! Dictionary with {} different hashtags.'.format(len(dictionary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with hashtags dataframes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>numberOfTweets</th>\n",
       "      <th>text</th>\n",
       "      <th>latitude</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-02</th>\n",
       "      <td>7.33389</td>\n",
       "      <td>11</td>\n",
       "      <td>Le service du vin chez #ilcortile #mulhouse #c...</td>\n",
       "      <td>47.7475</td>\n",
       "      <td>ilcortile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            longitude  numberOfTweets  \\\n",
       "2016-08-02    7.33389              11   \n",
       "\n",
       "                                                         text  latitude  \\\n",
       "2016-08-02  Le service du vin chez #ilcortile #mulhouse #c...   47.7475   \n",
       "\n",
       "              hashtag  \n",
       "2016-08-02  ilcortile  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggDate(gp.get_group('twibisg')).head(3)\n",
    "# dictionary['twibisg'].head(3)\n",
    "print('Dictionary with hashtags dataframes:')\n",
    "dictionary[list(dictionary.keys())[5]].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting event detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters that define events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Parameters of an event:\n",
    "MIN_TOT_NB_TWEETS = 25 ## The hashtag must have happened at least this number of times to be considered.\n",
    "MIN_NB_DAYS_WITH_HASHTAGS = 3 ## The hashtags must appear at least this number of different days to be considered.\n",
    "MIN_NB_TWEETS_DURING_EVENT = 10 ## To be considered an event, the hashtag must happen at least this nb of times during the day.\n",
    "THRESHOLD_ANOMALY_FACTOR = 3 ## The occurence of a hashtag during a single day must be above the mean by this FACTOR\n",
    "                             ## multiplied by the std to be considered as an anomaly.\n",
    "MAX_DURATION_OF_EVENT = timedelta(days=30) ## The maximum number of days we consider an event can happen\n",
    "MIN_DURATION_BEFORE_NEW_EVENT = timedelta(days=304) ## (= 10 months) The min time that should pass before an event can happen\n",
    "                                                    ## again and still be considered as event (ie. Christmas is an event\n",
    "                                                    ## each year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to detect recurrent events that should be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isSpecificEventListIllegal(detectedEventDateList):\n",
    "    '''\n",
    "    Return true if the list of dates contain illegal tupples of events, so if the event is recurrent\n",
    "    which would mean it is not a real event.\n",
    "    '''\n",
    "    def datesAreIllegal(date1, date2, date3):\n",
    "        '''\n",
    "        Return true if the 3 dates are not to be considered as regular events.\n",
    "        '''\n",
    "        ## Return if the difference is too small to be considered as 2 different events\n",
    "        def diffIsSmall(timeDiff):  \n",
    "            return timeDiff < MAX_DURATION_OF_EVENT\n",
    "\n",
    "        ## Return true if the difference is not big enough to be an annual event.\n",
    "        def isDiffSuspect(timeDiff):\n",
    "            return timeDiff < MIN_DURATION_BEFORE_NEW_EVENT   \n",
    "\n",
    "        diff1 = abs(date1 - date2)\n",
    "        diff2 = abs(date2 - date3)\n",
    "        diff3 = abs(date3 - date1)\n",
    "\n",
    "        ## The difference is too small, it must be the same event\n",
    "        if diffIsSmall(diff1) or diffIsSmall(diff2) or diffIsSmall(diff3):\n",
    "            return False\n",
    "\n",
    "        ## If there are at least 2 out of 3 suspect difference, then the dates are illegal\n",
    "        if isDiffSuspect(diff1):\n",
    "            return isDiffSuspect(diff2) or isDiffSuspect(diff3)\n",
    "        else:\n",
    "            return isDiffSuspect(diff2) and isDiffSuspect(diff3)\n",
    "    \n",
    "    ## MAIN FUNCTION : ##\n",
    "    # Go through the list of events and try all \"triples\" to see if there is any illegal triples. This is a quickly done\n",
    "    # code to do that. Code complexity bellow is in O(k^3), with k being the size of the list. We will apply this function\n",
    "    # to n list so we will have an overall complexity in O(n*k^3). We can consider however that each list will\n",
    "    # be small so k can be considered as constant and therefore the overall complexity will be in O(n).\n",
    "    for i in range(len(detectedEventDateList) - 2):\n",
    "        for j in range(i, len(detectedEventDateList) - 1):\n",
    "            for k in range(j, len(detectedEventDateList)):\n",
    "                if datesAreIllegal(detectedEventDateList[i], detectedEventDateList[j], detectedEventDateList[k]):\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:50:25 Starting to compute 607601 dict items to detect event. (4 min)\n",
      "13:50:36 10%\n",
      "13:50:46 20%\n",
      "13:50:57 30%\n",
      "13:51:07 40%\n",
      "13:51:18 50%\n",
      "13:51:28 60%\n",
      "13:51:39 70%\n",
      "13:51:49 80%\n",
      "13:52:00 90%\n",
      "13:52:10 100%\n",
      "13:52:10 Finished! Number of events detected = 3538\n"
     ]
    }
   ],
   "source": [
    "pr('Starting to compute {} dict items to detect event. (4 min)'.format(len(dictionary)))\n",
    "nbOfEventDetected = 0\n",
    "count = 0\n",
    "printingValue = int(len(dictionary) / 10)\n",
    "for [h,df] in dictionary.items():\n",
    "    count += 1\n",
    "    if count % printingValue == 0:\n",
    "        pr(\"{:.0f}%\".format(count/len(dictionary)*100))\n",
    "    df['event'] = False\n",
    "    if len(df) > MIN_NB_DAYS_WITH_HASHTAGS:\n",
    "        if df['numberOfTweets'].sum() > MIN_TOT_NB_TWEETS:\n",
    "            threshold = df['numberOfTweets'].mean() + THRESHOLD_ANOMALY_FACTOR * df['numberOfTweets'].std()\n",
    "            df['event'] = df.numberOfTweets.apply(lambda x: x > threshold and x > MIN_NB_TWEETS_DURING_EVENT)\n",
    "            \n",
    "            ## Remove recurrent events:\n",
    "            detectedEventDf = df[df['event']]\n",
    "            if len(detectedEventDf) > 3 and isSpecificEventListIllegal(detectedEventDf.index):\n",
    "                df['event'] = False\n",
    "            nbOfEventDetected += len(df[df['event']])\n",
    "pr('Finished! Number of events detected = {}'.format(nbOfEventDetected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making single event dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eventRowsList = []\n",
    "def applyToMakeEventDf(row):\n",
    "    if row.event:\n",
    "        rowToAdd = {'date': row.name, 'hashtag': row.hashtag, 'text': row.text,\n",
    "                    'longitude': row.longitude, 'latitude':row.latitude, 'numberOfTweets': row.numberOfTweets, }\n",
    "        eventRowsList.append(rowToAdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:52:10 Starting to make event df with 607601 dataframes. (around 6 min)\n",
      "13:52:41 10%\n",
      "13:53:11 20%\n",
      "13:53:41 30%\n",
      "13:54:11 40%\n",
      "13:54:42 50%\n",
      "13:55:12 60%\n",
      "13:55:42 70%\n",
      "13:56:12 80%\n",
      "13:56:42 90%\n",
      "13:57:12 100%\n",
      "13:57:12 Making new dataframe.\n",
      "13:57:12 Finished! Dataframe with 3538 rows\n"
     ]
    }
   ],
   "source": [
    "eventRowsList = []\n",
    "count = 0\n",
    "printingValue = int(len(dictionary) / 10)\n",
    "\n",
    "pr('Starting to make event df with {} dataframes. (around 6 min)'.format(len(dictionary)))\n",
    "for h, df in dictionary.items():\n",
    "    count += 1\n",
    "    if count % printingValue == 0:\n",
    "        pr(\"{:.0f}%\".format(count/len(dictionary)*100))\n",
    "        \n",
    "    ########## CHANGE DF TO MERGE CLOSE EVENTS ################\n",
    "    \n",
    "    df.apply(applyToMakeEventDf, axis=1)\n",
    "\n",
    "pr('Making new dataframe.')\n",
    "new_events = pd.DataFrame(eventRowsList)\n",
    "new_events.set_index(['date'], inplace=True)\n",
    "pr('Finished! Dataframe with {} rows'.format(len(new_events)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>numberOfTweets</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-21</th>\n",
       "      <td>スイス情報</td>\n",
       "      <td>46.96320</td>\n",
       "      <td>7.466670</td>\n",
       "      <td>28</td>\n",
       "      <td>#ベルナーオーバーライド #スイスアルプス #ヒマワリ と共に。#アイガー #メンヒ #ユン...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-10</th>\n",
       "      <td>winterwonderland</td>\n",
       "      <td>47.03460</td>\n",
       "      <td>8.303840</td>\n",
       "      <td>11</td>\n",
       "      <td>#winterwonderland @ Schneestern http://t.co/Ji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>winterwonderland</td>\n",
       "      <td>47.31875</td>\n",
       "      <td>8.544700</td>\n",
       "      <td>16</td>\n",
       "      <td>Im lovin it!!! #winterwonderland http://t.co/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>winterwonderland</td>\n",
       "      <td>46.97250</td>\n",
       "      <td>7.747200</td>\n",
       "      <td>15</td>\n",
       "      <td>Todays #winterwonderland at http://t.co/HiBFem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-27</th>\n",
       "      <td>german</td>\n",
       "      <td>47.14870</td>\n",
       "      <td>9.521860</td>\n",
       "      <td>14</td>\n",
       "      <td>For #german people from #Groznyy, #Russia : Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-07</th>\n",
       "      <td>german</td>\n",
       "      <td>47.38430</td>\n",
       "      <td>8.529590</td>\n",
       "      <td>12</td>\n",
       "      <td>For #german people from #Peru : #Adidas Origin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-26</th>\n",
       "      <td>potterhead</td>\n",
       "      <td>47.74350</td>\n",
       "      <td>7.331990</td>\n",
       "      <td>14</td>\n",
       "      <td>Hey les #Potterhead. Tweetez tous :\\n#Potterhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>potterhead</td>\n",
       "      <td>47.74350</td>\n",
       "      <td>7.332010</td>\n",
       "      <td>11</td>\n",
       "      <td>Hey les #Potterhead !\\nDemain on fête la Batai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-04</th>\n",
       "      <td>saynotoracism</td>\n",
       "      <td>47.20210</td>\n",
       "      <td>6.397690</td>\n",
       "      <td>20</td>\n",
       "      <td>#SayNoToRacism_$$$_#SayNoToRacism j'adhère on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-22</th>\n",
       "      <td>whatsappdown</td>\n",
       "      <td>45.98865</td>\n",
       "      <td>8.770820</td>\n",
       "      <td>30</td>\n",
       "      <td>#whatsappdown #Sanremo2014 bah buon sabato ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-13</th>\n",
       "      <td>qna</td>\n",
       "      <td>46.43360</td>\n",
       "      <td>6.940600</td>\n",
       "      <td>17</td>\n",
       "      <td>Both RT“@Questionnier: Sex or hanging out with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11</th>\n",
       "      <td>tedxnations</td>\n",
       "      <td>46.22660</td>\n",
       "      <td>6.140560</td>\n",
       "      <td>41</td>\n",
       "      <td>Final preparations, rehearsals, sound checks ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-25</th>\n",
       "      <td>secretstory6</td>\n",
       "      <td>46.20290</td>\n",
       "      <td>6.203860</td>\n",
       "      <td>21</td>\n",
       "      <td>Tous devant TF1!!! Let's go...!! #SecretStory6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-26</th>\n",
       "      <td>wipkingen</td>\n",
       "      <td>47.39260</td>\n",
       "      <td>8.521390</td>\n",
       "      <td>13</td>\n",
       "      <td>The band \"Cheibe Balagan\" at the #openair #wip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-13</th>\n",
       "      <td>ps</td>\n",
       "      <td>46.52430</td>\n",
       "      <td>6.865800</td>\n",
       "      <td>13</td>\n",
       "      <td>@chezlalah Oui, mais au moins y'a convergence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-04</th>\n",
       "      <td>walk</td>\n",
       "      <td>47.20990</td>\n",
       "      <td>9.712000</td>\n",
       "      <td>15</td>\n",
       "      <td>#myplace #place #austria #vorarlberg #schnifis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-17</th>\n",
       "      <td>ch</td>\n",
       "      <td>47.55640</td>\n",
       "      <td>7.591630</td>\n",
       "      <td>20</td>\n",
       "      <td>Elizabethenkirche #Bâle #Basel #Switzerland #s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-14</th>\n",
       "      <td>ch</td>\n",
       "      <td>46.20040</td>\n",
       "      <td>6.146300</td>\n",
       "      <td>13</td>\n",
       "      <td>#Escalade #vielleville #genève #GE #Suisse #sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-07</th>\n",
       "      <td>skymotori</td>\n",
       "      <td>45.87670</td>\n",
       "      <td>9.642520</td>\n",
       "      <td>19</td>\n",
       "      <td>Ieri Fernando ha detto che potrebbe restare in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-21</th>\n",
       "      <td>skymotori</td>\n",
       "      <td>45.87670</td>\n",
       "      <td>9.642530</td>\n",
       "      <td>21</td>\n",
       "      <td>@SkySportF1HD #SkyMotori  buongiorno!! A casa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-24</th>\n",
       "      <td>armstrong</td>\n",
       "      <td>45.99810</td>\n",
       "      <td>8.791940</td>\n",
       "      <td>13</td>\n",
       "      <td>Non posso e non ci voglio credere...perché??No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-14</th>\n",
       "      <td>tal</td>\n",
       "      <td>46.77150</td>\n",
       "      <td>6.641420</td>\n",
       "      <td>11</td>\n",
       "      <td>Normal c'est la meilleure !\\n#Tal #NMA _$$$_N'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-08</th>\n",
       "      <td>wimbledon</td>\n",
       "      <td>46.41950</td>\n",
       "      <td>7.438525</td>\n",
       "      <td>34</td>\n",
       "      <td>@mme_oh Niemand will, dass Andy Murray gewinnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-07</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.52070</td>\n",
       "      <td>7.290880</td>\n",
       "      <td>15</td>\n",
       "      <td>Kyran wins 3.1 and gains some revenge on the I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-08</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.14000</td>\n",
       "      <td>8.156055</td>\n",
       "      <td>20</td>\n",
       "      <td>So #cold in #bormio #ice @ Bormio http://t.co/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-18</th>\n",
       "      <td>cold</td>\n",
       "      <td>47.41270</td>\n",
       "      <td>8.271230</td>\n",
       "      <td>11</td>\n",
       "      <td>It's gonna be a great day!!! But it is still -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-16</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.24105</td>\n",
       "      <td>7.822870</td>\n",
       "      <td>14</td>\n",
       "      <td>So cold here in the mountains #cold #minus #de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-28</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.37470</td>\n",
       "      <td>8.424800</td>\n",
       "      <td>24</td>\n",
       "      <td>@SuperKaylie nothing much :( sooo boring out h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.58530</td>\n",
       "      <td>7.961250</td>\n",
       "      <td>23</td>\n",
       "      <td>#cold #jungfraujoch #swiss #switzerland #son p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-27</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.29190</td>\n",
       "      <td>8.310650</td>\n",
       "      <td>17</td>\n",
       "      <td>Então mas como é que está o tempo aí em Portug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.48555</td>\n",
       "      <td>7.669455</td>\n",
       "      <td>14</td>\n",
       "      <td>-15 #cold #fitness #MondayMotivation @jordanfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.15210</td>\n",
       "      <td>8.549090</td>\n",
       "      <td>11</td>\n",
       "      <td>#winter #cold #holidays #snow  #snowing #blizz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.28625</td>\n",
       "      <td>7.945245</td>\n",
       "      <td>12</td>\n",
       "      <td>Iced Dolphins #cold #ice #dolphin #games #moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>cold</td>\n",
       "      <td>47.16690</td>\n",
       "      <td>8.544600</td>\n",
       "      <td>11</td>\n",
       "      <td>#Doxis #snow #Zurich #flughafen #winter #cold ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-17</th>\n",
       "      <td>cold</td>\n",
       "      <td>46.50750</td>\n",
       "      <td>8.266670</td>\n",
       "      <td>11</td>\n",
       "      <td>#cold @ Zürich, Switzerland https://t.co/gq3eP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-17</th>\n",
       "      <td>allstargame</td>\n",
       "      <td>46.21825</td>\n",
       "      <td>6.147490</td>\n",
       "      <td>24</td>\n",
       "      <td>Hahahahahaha ils delirent trop ces ricains..!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>bugatti</td>\n",
       "      <td>46.23410</td>\n",
       "      <td>6.119070</td>\n",
       "      <td>12</td>\n",
       "      <td>Engine from the Bugatti Chiron. As big as a Sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-12</th>\n",
       "      <td>hollandedemission</td>\n",
       "      <td>46.05775</td>\n",
       "      <td>6.497035</td>\n",
       "      <td>12</td>\n",
       "      <td>Valérie s'est installée à l'Elysée et maintena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-18</th>\n",
       "      <td>amas</td>\n",
       "      <td>45.96010</td>\n",
       "      <td>8.692790</td>\n",
       "      <td>111</td>\n",
       "      <td>Ventiquattro, @onedirection  #AMAs #AOTY \\n1rt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-20</th>\n",
       "      <td>amas</td>\n",
       "      <td>46.20240</td>\n",
       "      <td>6.131470</td>\n",
       "      <td>116</td>\n",
       "      <td>\"@1DUpdateBRA: DÊ RT E FAÇA QUOTE. AJUDE NA VO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-19</th>\n",
       "      <td>road</td>\n",
       "      <td>46.17370</td>\n",
       "      <td>7.070900</td>\n",
       "      <td>49</td>\n",
       "      <td>#road #switzerland #parking #geneva #road #bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-20</th>\n",
       "      <td>road</td>\n",
       "      <td>46.24220</td>\n",
       "      <td>6.202300</td>\n",
       "      <td>49</td>\n",
       "      <td>#road #rainy #rain #day #amazing #view #nature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-07</th>\n",
       "      <td>outstanding</td>\n",
       "      <td>46.94950</td>\n",
       "      <td>8.223950</td>\n",
       "      <td>39</td>\n",
       "      <td>Keep Calm cauz Adidas #Outstanding #Love #Jack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-17</th>\n",
       "      <td>outstanding</td>\n",
       "      <td>46.81320</td>\n",
       "      <td>8.223950</td>\n",
       "      <td>45</td>\n",
       "      <td>For All the people from #Philadelphia, #PA : A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-22</th>\n",
       "      <td>weihnachten</td>\n",
       "      <td>46.74960</td>\n",
       "      <td>7.543760</td>\n",
       "      <td>17</td>\n",
       "      <td>Esse Avocado!Hab was gutzumachen...ob's Hilft ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-24</th>\n",
       "      <td>weihnachten</td>\n",
       "      <td>47.65340</td>\n",
       "      <td>8.763865</td>\n",
       "      <td>16</td>\n",
       "      <td>Möge das Christkind Haloperidol bringen. #Weih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-24</th>\n",
       "      <td>weihnachten</td>\n",
       "      <td>47.51370</td>\n",
       "      <td>8.523560</td>\n",
       "      <td>11</td>\n",
       "      <td>Wir wünschen euch frohe #Weihnachten und einen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-24</th>\n",
       "      <td>weihnachten</td>\n",
       "      <td>47.06435</td>\n",
       "      <td>9.123565</td>\n",
       "      <td>12</td>\n",
       "      <td>Hör dir Die Roten Rosen auf @AppleMusic an. #w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-25</th>\n",
       "      <td>lbesp3</td>\n",
       "      <td>46.73460</td>\n",
       "      <td>6.249990</td>\n",
       "      <td>195</td>\n",
       "      <td>Ce soir #LBESP3 @alexgu18_$$$_Le roux si il re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-05</th>\n",
       "      <td>teamturc</td>\n",
       "      <td>47.73430</td>\n",
       "      <td>7.295800</td>\n",
       "      <td>16</td>\n",
       "      <td>Moi j'aime bien pas vous #TeamTurc #metisse #a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      hashtag  latitude  longitude  numberOfTweets  \\\n",
       "date                                                                 \n",
       "2016-07-21              スイス情報  46.96320   7.466670              28   \n",
       "2013-02-10   winterwonderland  47.03460   8.303840              11   \n",
       "2014-12-28   winterwonderland  47.31875   8.544700              16   \n",
       "2014-12-29   winterwonderland  46.97250   7.747200              15   \n",
       "2014-03-27             german  47.14870   9.521860              14   \n",
       "2014-04-07             german  47.38430   8.529590              12   \n",
       "2013-04-26         potterhead  47.74350   7.331990              14   \n",
       "2013-05-01         potterhead  47.74350   7.332010              11   \n",
       "2014-07-04      saynotoracism  47.20210   6.397690              20   \n",
       "2014-02-22       whatsappdown  45.98865   8.770820              30   \n",
       "2013-05-13                qna  46.43360   6.940600              17   \n",
       "2014-12-11        tedxnations  46.22660   6.140560              41   \n",
       "2012-05-25       secretstory6  46.20290   6.203860              21   \n",
       "2016-06-26          wipkingen  47.39260   8.521390              13   \n",
       "2012-05-13                 ps  46.52430   6.865800              13   \n",
       "2012-11-04               walk  47.20990   9.712000              15   \n",
       "2013-10-17                 ch  47.55640   7.591630              20   \n",
       "2013-12-14                 ch  46.20040   6.146300              13   \n",
       "2014-11-07          skymotori  45.87670   9.642520              19   \n",
       "2014-11-21          skymotori  45.87670   9.642530              21   \n",
       "2012-08-24          armstrong  45.99810   8.791940              13   \n",
       "2013-12-14                tal  46.77150   6.641420              11   \n",
       "2012-07-08          wimbledon  46.41950   7.438525              34   \n",
       "2012-12-07               cold  46.52070   7.290880              15   \n",
       "2012-12-08               cold  46.14000   8.156055              20   \n",
       "2013-01-18               cold  47.41270   8.271230              11   \n",
       "2013-02-16               cold  46.24105   7.822870              14   \n",
       "2013-12-28               cold  46.37470   8.424800              24   \n",
       "2013-12-31               cold  46.58530   7.961250              23   \n",
       "2014-12-27               cold  46.29190   8.310650              17   \n",
       "2014-12-29               cold  46.48555   7.669455              14   \n",
       "2014-12-30               cold  46.15210   8.549090              11   \n",
       "2014-12-31               cold  46.28625   7.945245              12   \n",
       "2015-01-01               cold  47.16690   8.544600              11   \n",
       "2016-01-17               cold  46.50750   8.266670              11   \n",
       "2014-02-17        allstargame  46.21825   6.147490              24   \n",
       "2016-03-01            bugatti  46.23410   6.119070              12   \n",
       "2014-01-12  hollandedemission  46.05775   6.497035              12   \n",
       "2014-11-18               amas  45.96010   8.692790             111   \n",
       "2014-11-20               amas  46.20240   6.131470             116   \n",
       "2013-10-19               road  46.17370   7.070900              49   \n",
       "2013-10-20               road  46.24220   6.202300              49   \n",
       "2014-04-07        outstanding  46.94950   8.223950              39   \n",
       "2014-04-17        outstanding  46.81320   8.223950              45   \n",
       "2013-12-22        weihnachten  46.74960   7.543760              17   \n",
       "2013-12-24        weihnachten  47.65340   8.763865              16   \n",
       "2014-12-24        weihnachten  47.51370   8.523560              11   \n",
       "2015-12-24        weihnachten  47.06435   9.123565              12   \n",
       "2013-11-25             lbesp3  46.73460   6.249990             195   \n",
       "2014-03-05           teamturc  47.73430   7.295800              16   \n",
       "\n",
       "                                                         text  \n",
       "date                                                           \n",
       "2016-07-21  #ベルナーオーバーライド #スイスアルプス #ヒマワリ と共に。#アイガー #メンヒ #ユン...  \n",
       "2013-02-10  #winterwonderland @ Schneestern http://t.co/Ji...  \n",
       "2014-12-28  Im lovin it!!! #winterwonderland http://t.co/f...  \n",
       "2014-12-29  Todays #winterwonderland at http://t.co/HiBFem...  \n",
       "2014-03-27  For #german people from #Groznyy, #Russia : Ad...  \n",
       "2014-04-07  For #german people from #Peru : #Adidas Origin...  \n",
       "2013-04-26  Hey les #Potterhead. Tweetez tous :\\n#Potterhe...  \n",
       "2013-05-01  Hey les #Potterhead !\\nDemain on fête la Batai...  \n",
       "2014-07-04  #SayNoToRacism_$$$_#SayNoToRacism j'adhère on ...  \n",
       "2014-02-22  #whatsappdown #Sanremo2014 bah buon sabato ser...  \n",
       "2013-05-13  Both RT“@Questionnier: Sex or hanging out with...  \n",
       "2014-12-11  Final preparations, rehearsals, sound checks ....  \n",
       "2012-05-25  Tous devant TF1!!! Let's go...!! #SecretStory6...  \n",
       "2016-06-26  The band \"Cheibe Balagan\" at the #openair #wip...  \n",
       "2012-05-13  @chezlalah Oui, mais au moins y'a convergence ...  \n",
       "2012-11-04  #myplace #place #austria #vorarlberg #schnifis...  \n",
       "2013-10-17  Elizabethenkirche #Bâle #Basel #Switzerland #s...  \n",
       "2013-12-14  #Escalade #vielleville #genève #GE #Suisse #sw...  \n",
       "2014-11-07  Ieri Fernando ha detto che potrebbe restare in...  \n",
       "2014-11-21  @SkySportF1HD #SkyMotori  buongiorno!! A casa ...  \n",
       "2012-08-24  Non posso e non ci voglio credere...perché??No...  \n",
       "2013-12-14  Normal c'est la meilleure !\\n#Tal #NMA _$$$_N'...  \n",
       "2012-07-08  @mme_oh Niemand will, dass Andy Murray gewinnt...  \n",
       "2012-12-07  Kyran wins 3.1 and gains some revenge on the I...  \n",
       "2012-12-08  So #cold in #bormio #ice @ Bormio http://t.co/...  \n",
       "2013-01-18  It's gonna be a great day!!! But it is still -...  \n",
       "2013-02-16  So cold here in the mountains #cold #minus #de...  \n",
       "2013-12-28  @SuperKaylie nothing much :( sooo boring out h...  \n",
       "2013-12-31  #cold #jungfraujoch #swiss #switzerland #son p...  \n",
       "2014-12-27  Então mas como é que está o tempo aí em Portug...  \n",
       "2014-12-29  -15 #cold #fitness #MondayMotivation @jordanfi...  \n",
       "2014-12-30  #winter #cold #holidays #snow  #snowing #blizz...  \n",
       "2014-12-31  Iced Dolphins #cold #ice #dolphin #games #moun...  \n",
       "2015-01-01  #Doxis #snow #Zurich #flughafen #winter #cold ...  \n",
       "2016-01-17  #cold @ Zürich, Switzerland https://t.co/gq3eP...  \n",
       "2014-02-17  Hahahahahaha ils delirent trop ces ricains..!!...  \n",
       "2016-03-01  Engine from the Bugatti Chiron. As big as a Sm...  \n",
       "2014-01-12  Valérie s'est installée à l'Elysée et maintena...  \n",
       "2014-11-18  Ventiquattro, @onedirection  #AMAs #AOTY \\n1rt...  \n",
       "2014-11-20  \"@1DUpdateBRA: DÊ RT E FAÇA QUOTE. AJUDE NA VO...  \n",
       "2013-10-19  #road #switzerland #parking #geneva #road #bes...  \n",
       "2013-10-20  #road #rainy #rain #day #amazing #view #nature...  \n",
       "2014-04-07  Keep Calm cauz Adidas #Outstanding #Love #Jack...  \n",
       "2014-04-17  For All the people from #Philadelphia, #PA : A...  \n",
       "2013-12-22  Esse Avocado!Hab was gutzumachen...ob's Hilft ...  \n",
       "2013-12-24  Möge das Christkind Haloperidol bringen. #Weih...  \n",
       "2014-12-24  Wir wünschen euch frohe #Weihnachten und einen...  \n",
       "2015-12-24  Hör dir Die Roten Rosen auf @AppleMusic an. #w...  \n",
       "2013-11-25  Ce soir #LBESP3 @alexgu18_$$$_Le roux si il re...  \n",
       "2014-03-05  Moi j'aime bien pas vous #TeamTurc #metisse #a...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Events dataframe:')\n",
    "new_events.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked dataframe of all days:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>numberOfTweets</th>\n",
       "      <th>text</th>\n",
       "      <th>latitude</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-11-21</th>\n",
       "      <td>8.309655</td>\n",
       "      <td>2</td>\n",
       "      <td>ルツェルンも❄雪が降り始めました。寒いです〜。\\n#スイス情報_$$$_スイスのルツェルンも...</td>\n",
       "      <td>47.0569</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-01</th>\n",
       "      <td>8.309680</td>\n",
       "      <td>1</td>\n",
       "      <td>スイス・ローザンヌで国際バレエコンクールが有りましたね。\\n日本人、二山治雄さん優勝しました...</td>\n",
       "      <td>47.0569</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-03</th>\n",
       "      <td>8.309650</td>\n",
       "      <td>4</td>\n",
       "      <td>スイスで買えるHirse(穀物フレーク)\\nその名もBinbosan(ビンボさん)\\n響きが...</td>\n",
       "      <td>47.0569</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-04</th>\n",
       "      <td>8.309650</td>\n",
       "      <td>1</td>\n",
       "      <td>スイス・ルツェルンはどんよ～リした空模様。午後からは雨の予報です。\\n( ´Д｀)=3\\n#...</td>\n",
       "      <td>47.0569</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-05</th>\n",
       "      <td>8.309680</td>\n",
       "      <td>1</td>\n",
       "      <td>ルツェルンの図書館では、赤ちゃん用の本が無料で貰えるんですよ。\\nhttp://t.co/5...</td>\n",
       "      <td>47.0569</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-07</th>\n",
       "      <td>8.309700</td>\n",
       "      <td>3</td>\n",
       "      <td>六本木ヒルズでスイスを満喫！\\n☆祝150周年☆\\nhttp://t.co/JrsdL0BJ...</td>\n",
       "      <td>47.0569</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-10</th>\n",
       "      <td>8.309720</td>\n",
       "      <td>1</td>\n",
       "      <td>スイス産の離乳食。Bimbosanのお試しサイズ頼んでみました。\\nお試し出来るのはありがた...</td>\n",
       "      <td>47.0569</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-11</th>\n",
       "      <td>8.309230</td>\n",
       "      <td>1</td>\n",
       "      <td>スイスでストリートミュージック！\\n（ルツェルン）\\n#スイス情報 http://t.co/...</td>\n",
       "      <td>47.0546</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-12</th>\n",
       "      <td>8.314030</td>\n",
       "      <td>1</td>\n",
       "      <td>スイス・ルツェルンのゴミ箱。沢山あるのでゴミを捨てたいときに便利。\\n犬の糞も捨てられるよう...</td>\n",
       "      <td>47.0542</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-13</th>\n",
       "      <td>8.309680</td>\n",
       "      <td>1</td>\n",
       "      <td>スイス・ルツェルンも今日は晴れ時々雨。気温は10度と変なお天気。\\n#スイス情報</td>\n",
       "      <td>47.0569</td>\n",
       "      <td>スイス情報</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            longitude  numberOfTweets  \\\n",
       "2013-11-21   8.309655               2   \n",
       "2014-02-01   8.309680               1   \n",
       "2014-02-03   8.309650               4   \n",
       "2014-02-04   8.309650               1   \n",
       "2014-02-05   8.309680               1   \n",
       "2014-02-07   8.309700               3   \n",
       "2014-02-10   8.309720               1   \n",
       "2014-02-11   8.309230               1   \n",
       "2014-02-12   8.314030               1   \n",
       "2014-02-13   8.309680               1   \n",
       "\n",
       "                                                         text  latitude  \\\n",
       "2013-11-21  ルツェルンも❄雪が降り始めました。寒いです〜。\\n#スイス情報_$$$_スイスのルツェルンも...   47.0569   \n",
       "2014-02-01  スイス・ローザンヌで国際バレエコンクールが有りましたね。\\n日本人、二山治雄さん優勝しました...   47.0569   \n",
       "2014-02-03  スイスで買えるHirse(穀物フレーク)\\nその名もBinbosan(ビンボさん)\\n響きが...   47.0569   \n",
       "2014-02-04  スイス・ルツェルンはどんよ～リした空模様。午後からは雨の予報です。\\n( ´Д｀)=3\\n#...   47.0569   \n",
       "2014-02-05  ルツェルンの図書館では、赤ちゃん用の本が無料で貰えるんですよ。\\nhttp://t.co/5...   47.0569   \n",
       "2014-02-07  六本木ヒルズでスイスを満喫！\\n☆祝150周年☆\\nhttp://t.co/JrsdL0BJ...   47.0569   \n",
       "2014-02-10  スイス産の離乳食。Bimbosanのお試しサイズ頼んでみました。\\nお試し出来るのはありがた...   47.0569   \n",
       "2014-02-11  スイスでストリートミュージック！\\n（ルツェルン）\\n#スイス情報 http://t.co/...   47.0546   \n",
       "2014-02-12  スイス・ルツェルンのゴミ箱。沢山あるのでゴミを捨てたいときに便利。\\n犬の糞も捨てられるよう...   47.0542   \n",
       "2014-02-13           スイス・ルツェルンも今日は晴れ時々雨。気温は10度と変なお天気。\\n#スイス情報   47.0569   \n",
       "\n",
       "           hashtag  event  \n",
       "2013-11-21   スイス情報  False  \n",
       "2014-02-01   スイス情報  False  \n",
       "2014-02-03   スイス情報  False  \n",
       "2014-02-04   スイス情報  False  \n",
       "2014-02-05   スイス情報  False  \n",
       "2014-02-07   スイス情報  False  \n",
       "2014-02-10   スイス情報  False  \n",
       "2014-02-11   スイス情報  False  \n",
       "2014-02-12   スイス情報  False  \n",
       "2014-02-13   スイス情報  False  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Linked dataframe of all days:')\n",
    "dictionary[new_events.iloc[0].hashtag].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3538 events.\n"
     ]
    }
   ],
   "source": [
    "total_number_of_events = len(new_events)\n",
    "print('There are {} events.'.format(total_number_of_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>numberOfTweets</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>スイス情報</td>\n",
       "      <td>46.9632</td>\n",
       "      <td>7.46667</td>\n",
       "      <td>28</td>\n",
       "      <td>#ベルナーオーバーライド #スイスアルプス #ヒマワリ と共に。#アイガー #メンヒ #ユン...</td>\n",
       "      <td>2016-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hashtag  latitude  longitude  numberOfTweets  \\\n",
       "0   スイス情報   46.9632    7.46667              28   \n",
       "\n",
       "                                                text        date  \n",
       "0  #ベルナーオーバーライド #スイスアルプス #ヒマワリ と共に。#アイガー #メンヒ #ユン...  2016-07-21  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_df = new_events.copy()\n",
    "e_df['date'] = e_df.index\n",
    "e_df.index = [i for i in range (len(e_df))]\n",
    "e_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to generate the right datetimes for the jsons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_dt = datetime(1970, 1, 1)\n",
    "def to_utc(date):\n",
    "    d_dt = datetime.combine(date, datetime.min.time())\n",
    "    return int((d_dt - epoch_dt).total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_unix_time(record):\n",
    "    datetime_index = pd.DatetimeIndex([datetime(record['year'], record['month'], 1)])\n",
    "    unix_time_index = datetime_index.astype(np.int64) // 10**6\n",
    "    return unix_time_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:57:12 Converting dates...\n",
      "13:57:13 Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>numberOfTweets</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>utc_date</th>\n",
       "      <th>unix_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>スイス情報</td>\n",
       "      <td>46.9632</td>\n",
       "      <td>7.46667</td>\n",
       "      <td>28</td>\n",
       "      <td>#ベルナーオーバーライド #スイスアルプス #ヒマワリ と共に。#アイガー #メンヒ #ユン...</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>1469059200000</td>\n",
       "      <td>1467331200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hashtag  latitude  longitude  numberOfTweets  \\\n",
       "0   スイス情報   46.9632    7.46667              28   \n",
       "\n",
       "                                                text        date  year  month  \\\n",
       "0  #ベルナーオーバーライド #スイスアルプス #ヒマワリ と共に。#アイガー #メンヒ #ユン...  2016-07-21  2016      7   \n",
       "\n",
       "        utc_date      unix_time  \n",
       "0  1469059200000  1467331200000  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr('Converting dates...')\n",
    "e_df['year'] = e_df['date'].apply(lambda x: x.year)\n",
    "e_df['month'] = e_df['date'].apply(lambda x: x.month)\n",
    "e_df['utc_date'] = e_df['date'].apply(lambda x: to_utc(x))\n",
    "e_df['unix_time'] = e_df.apply(convert_to_unix_time, axis=1)\n",
    "pr('Done.')\n",
    "e_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by months and generating the dictionary for the json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_gb_month = e_df.groupby(e_df.unix_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:57:13 Making event list...\n",
      "13:57:17 Done.\n"
     ]
    }
   ],
   "source": [
    "pr('Making event list...')\n",
    "months = []\n",
    "for month, df in e_gb_month:\n",
    "    days = []\n",
    "    for i in range (len(df)):\n",
    "        ht = df.iloc[i]['hashtag']\n",
    "        lat = df.iloc[i]['latitude']\n",
    "        lon = df.iloc[i]['longitude']\n",
    "        t_num = df.iloc[i]['numberOfTweets']\n",
    "        tweets = df.iloc[i]['text'].split(delimiter)\n",
    "        date = df.iloc[i]['utc_date']\n",
    "        \n",
    "        data_unit = { 'name': ht\n",
    "                    , 'latitude' : lat\n",
    "                    , 'longitude' : lon\n",
    "                    , 'tweets' : tweets\n",
    "                    , 'number_of_tweets' : str(t_num)\n",
    "                    , 'date' : int(date)}\n",
    "        days.append(data_unit)\n",
    "    \n",
    "    curr_month = {'date': int(month), 'data' : days}\n",
    "    months.append(curr_month)\n",
    "\n",
    "final_events = {'events' : months}\n",
    "pr('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:57:17 Exporting to json...\n",
      "13:57:17 Export done. File \"export_twitter_events_2017-01-30_13h57min17_3538_events.json\" has been created.\n"
     ]
    }
   ],
   "source": [
    "exportFilename = 'export_twitter_events_' + datetime.now().strftime(\"%Y-%m-%d_%Hh%Mmin%S\") + \\\n",
    "'_' + str(total_number_of_events)+ '_events.json'\n",
    "exportPath =  os.path.join('data', exportFilename)\n",
    "\n",
    "pr('Exporting to json...')\n",
    "with open(exportPath, 'w') as f:\n",
    "     json.dump(final_events, f)\n",
    "pr('Export done. File \"{}\" has been created.'.format(exportFilename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ADA-kernel]",
   "language": "python",
   "name": "conda-env-ADA-kernel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
